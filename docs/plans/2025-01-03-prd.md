# Product Requirements Document (PRD)

**Project:** Dog FACS Dataset
**Version:** 1.0
**Date:** 2025-01-03
**Authors:** Danylo Lohachov, Danylo Zherzdiev, Anton Shkrebela, Mariia Volkova
**Supervisor:** dr hab. inż. Michał Czubenko

---

## 1. Executive Summary

Dog FACS Dataset is an AI-powered annotation pipeline and dataset for dog emotion analysis. The project delivers:
1. An AI application capable of automatic frame annotation
2. A publicly available dataset of 25,000+ annotated frames in COCO format
3. A demo application for visualization and verification

---

## 2. Problem Statement

Current dog emotion research lacks:
- Large-scale, publicly available datasets with comprehensive annotations
- Standardized annotation format compatible with existing ML tools
- Automated annotation pipelines to reduce manual labeling effort

This project addresses these gaps by creating both the tooling and the dataset.

---

## 3. Goals and Success Criteria

### 3.1 AI Pipeline (Semester 1)

| Metric | Target |
|--------|--------|
| Dog detection accuracy (mAP) | > 85% |
| Breed classification (Top-5 accuracy) | > 80% |
| Keypoint localization (PCK@0.1) | > 75% |
| Emotion classification accuracy | > 70% |

### 3.2 Dataset (Semester 2)

| Metric | Target |
|--------|--------|
| Total annotated frames | ≥ 25,000 |
| Manually verified frames | ~6,250 (25%) |
| Auto vs manual annotation agreement | ≥ 85% |
| Emotion class balance | ≥ 5% per class |
| Breed diversity | ≥ 20 breeds |
| COCO format compliance | 100% |

---

## 4. Scope

### 4.1 In Scope

**Semester 1 - AI Pipeline Development:**
- Dog bounding box detection model (YOLOv8)
- Breed classification model (ViT/EfficientNet)
- Facial keypoint detection model (HRNet, 20+ points)
- Emotion classification model (DogFACS-based)
- Unified inference pipeline
- Streamlit demo application

**Semester 2 - Dataset Creation:**
- Collection of ~2,500 YouTube videos (~20 sec each)
- Automatic annotation of 25,000 frames
- Manual verification of 25% sample
- COCO format export
- Dataset statistics and final report

### 4.2 Out of Scope

- Real-time video processing
- Mobile application deployment
- Model training from scratch (using transfer learning)
- Multi-dog detection in single frame (v1.0)
- Audio analysis

---

## 5. Functional Requirements

### FR-1: Dog Detection
- **FR-1.1:** System shall detect dogs in images/video frames
- **FR-1.2:** System shall output bounding box in format `[x, y, width, height]`
- **FR-1.3:** System shall provide confidence score for each detection
- **FR-1.4:** System shall handle images of varying resolutions

### FR-2: Breed Classification
- **FR-2.1:** System shall classify detected dogs into predefined breed categories
- **FR-2.2:** System shall support minimum 50 breed classes
- **FR-2.3:** System shall provide Top-5 predictions with confidence scores
- **FR-2.4:** System shall include "mixed/unknown" category

### FR-3: Keypoint Detection
- **FR-3.1:** System shall detect minimum 20 facial keypoints per dog
- **FR-3.2:** Keypoints shall include: eyes, nose, ears, mouth corners, muzzle outline
- **FR-3.3:** System shall output keypoint coordinates in format `[x, y, visibility]`
- **FR-3.4:** System shall handle partial occlusions

### FR-4: Emotion Classification
- **FR-4.1:** System shall classify dog emotions based on DogFACS methodology
- **FR-4.2:** System shall support emotion categories: happy, sad, angry, fearful, relaxed, neutral
- **FR-4.3:** System shall use keypoint features as input
- **FR-4.4:** System shall provide confidence scores per emotion

### FR-5: Pipeline Integration
- **FR-5.1:** System shall process single images through all models sequentially
- **FR-5.2:** System shall extract frames from video files
- **FR-5.3:** System shall batch process multiple frames
- **FR-5.4:** System shall output annotations in COCO JSON format

### FR-6: Demo Application
- **FR-6.1:** User shall upload image or video file
- **FR-6.2:** System shall display annotated results with visual overlays
- **FR-6.3:** User shall view bounding box, keypoints, breed, and emotion
- **FR-6.4:** User shall export annotations as JSON

### FR-7: Dataset Output
- **FR-7.1:** Dataset shall be in COCO format with all required fields
- **FR-7.2:** Dataset shall include images, annotations, and categories sections
- **FR-7.3:** Each annotation shall contain: bbox, breed_id, keypoints, emotion_id
- **FR-7.4:** Dataset shall include metadata: source video, frame number, timestamp

---

## 6. Non-Functional Requirements

### NFR-1: Performance
- Single frame inference: < 500ms on GPU
- Batch processing: > 10 frames/second on GPU
- Demo app response time: < 3 seconds for single image

### NFR-2: Compatibility
- Python 3.10+
- PyTorch 2.0+
- CUDA 11.8+ (for GPU acceleration)
- Cross-platform: Linux, macOS, Windows

### NFR-3: Data Quality
- Minimum image resolution: 480x360
- Frame extraction rate: 1 FPS from videos
- No duplicate frames in dataset

### NFR-4: Documentation
- Code documentation with docstrings
- API documentation for pipeline
- Dataset documentation with statistics

---

## 7. Data Requirements

### 7.1 Input Data Sources

| Source | Type | Usage |
|--------|------|-------|
| HuggingFace: Dewa/Dog_Emotion_Dataset_v2 | Images | Training emotion model |
| HuggingFace: Q-b1t/Dogs_Emotions_Dataset | Images | Training emotion model |
| Kaggle: Dog Emotions Prediction | Images | Training emotion model |
| Kaggle: Dog Emotions - 5 Classes | Images | Training emotion model |
| Kaggle: DogFLW | Keypoints | Training keypoint model |
| YouTube videos | Videos | Dataset creation |

### 7.2 Output Data Format (COCO)

```json
{
  "info": { "description": "Dog FACS Dataset", "version": "1.0" },
  "licenses": [],
  "images": [
    { "id": 1, "file_name": "frame_0001.jpg", "width": 1920, "height": 1080 }
  ],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "bbox": [100, 150, 200, 250],
      "keypoints": [x1, y1, v1, x2, y2, v2, ...],
      "breed_id": 15,
      "emotion_id": 2,
      "confidence": { "bbox": 0.95, "breed": 0.87, "emotion": 0.72 }
    }
  ],
  "categories": [
    { "id": 1, "name": "dog", "keypoints": ["left_eye", "right_eye", ...] }
  ]
}
```

---

## 8. User Roles

| Role | Description | Primary Actions |
|------|-------------|-----------------|
| Researcher | Uses dataset for ML research | Download dataset, view statistics |
| Annotator | Manually verifies annotations | Review frames, correct labels |
| Developer | Builds and maintains pipeline | Train models, integrate pipeline |
| Presenter | Demonstrates at university | Run demo, show results |

---

## 9. Deliverables

### Milestone 1 (End of Semester 1)
- [ ] Trained dog detection model (YOLOv8)
- [ ] Trained breed classification model
- [ ] Trained keypoint detection model (HRNet)
- [ ] Trained emotion classification model
- [ ] Integrated inference pipeline
- [ ] Streamlit demo application
- [ ] Technical documentation

### Milestone 2 (End of Semester 2)
- [ ] 2,500 collected YouTube videos
- [ ] 25,000 auto-annotated frames
- [ ] 6,250 manually verified frames
- [ ] COCO format dataset file
- [ ] Dataset statistics report
- [ ] Final project report
- [ ] Presentation materials

---

## 10. Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Model accuracy below target | High | Use pretrained models, augment training data |
| Insufficient GPU resources | High | Use university cluster, Google Colab |
| YouTube video availability | Medium | Download early, maintain backup sources |
| Manual verification bottleneck | Medium | Clear guidelines, divide work equally |
| COCO format compatibility issues | Low | Validate early with pycocotools |

---

## 11. Dependencies

### External Dependencies
- Pre-trained model weights (YOLO, HRNet, ViT)
- Training datasets from HuggingFace/Kaggle
- YouTube video access
- GPU compute resources

### Internal Dependencies
- BBox model required before breed/keypoint models
- Keypoint model required before emotion model
- Pipeline required before batch annotation

---

## 12. Glossary

| Term | Definition |
|------|------------|
| COCO | Common Objects in Context - standard annotation format |
| DogFACS | Dog Facial Action Coding System - methodology for coding dog facial expressions |
| mAP | Mean Average Precision - object detection metric |
| PCK | Percentage of Correct Keypoints - keypoint detection metric |
| Keypoints | Specific anatomical points on dog face (eyes, nose, ears, etc.) |
| Poselet | Part-based pose representation |
