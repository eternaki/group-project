# Story 3.2: Classifier Fine-tuning

**Status:** To Do
**Assignee:** U3 (Danylo Zherzdiev)
**Priority:** High
**Sprint:** 3 - Breed Classification

---

## Description

As an ML engineer, I want to train a breed classifier using transfer learning.

---

## Acceptance Criteria

- [ ] Architecture selected (ViT or EfficientNet)
- [ ] Training script created
- [ ] Model trained with proper learning rate schedule
- [ ] Best checkpoint selected based on validation accuracy

---

## Tasks

- [ ] Choose architecture based on Sprint 1 research
- [ ] Load pretrained weights from timm
- [ ] Replace classification head for 50+ classes
- [ ] Configure training hyperparameters
- [ ] Implement training loop with validation
- [ ] Save best model checkpoint

---

## Training Script

```python
# scripts/training/train_breed.py

import torch
import timm
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets

# Load pretrained model
model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=50)

# Training transforms
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.2, 0.2, 0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Training config
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)
criterion = nn.CrossEntropyLoss()
```

---

## Hyperparameters

| Parameter | Value |
|-----------|-------|
| epochs | 50 |
| batch_size | 32 |
| learning_rate | 1e-4 |
| weight_decay | 0.01 |
| optimizer | AdamW |
| scheduler | CosineAnnealing |

---

## Output

- `scripts/training/train_breed.py`
- `runs/breed/best.pt`
