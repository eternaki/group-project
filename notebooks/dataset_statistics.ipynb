{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog FACS Dataset - Analiza Statystyk\n",
    "\n",
    "Notebook do analizy statystyk finalnego datasetu Dog FACS.\n",
    "\n",
    "**Zawartość:**\n",
    "1. Wczytanie danych\n",
    "2. Ogólne statystyki\n",
    "3. Rozkład emocji\n",
    "4. Rozkład ras\n",
    "5. Analiza keypoints\n",
    "6. Rozkład confidence scores\n",
    "7. Podsumowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Konfiguracja wykresów\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Biblioteki załadowane.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wczytanie Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżki do plików\n",
    "DATA_DIR = Path('../data')\n",
    "ANNOTATIONS_PATH = DATA_DIR / 'annotations' / 'merged.json'\n",
    "\n",
    "# Alternatywne ścieżki dla finalnego datasetu\n",
    "FINAL_DIR = DATA_DIR / 'final' / 'dog-facs-dataset' / 'annotations'\n",
    "TRAIN_PATH = FINAL_DIR / 'train.json'\n",
    "VAL_PATH = FINAL_DIR / 'val.json'\n",
    "TEST_PATH = FINAL_DIR / 'test.json'\n",
    "\n",
    "def load_coco(path: Path) -> dict:\n",
    "    \"\"\"Wczytuje plik COCO.\"\"\"\n",
    "    if not path.exists():\n",
    "        print(f'Plik nie istnieje: {path}')\n",
    "        return {'images': [], 'annotations': [], 'categories': []}\n",
    "    \n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Wczytaj dane\n",
    "if ANNOTATIONS_PATH.exists():\n",
    "    data = load_coco(ANNOTATIONS_PATH)\n",
    "    print(f'Wczytano z: {ANNOTATIONS_PATH}')\n",
    "elif TRAIN_PATH.exists():\n",
    "    # Połącz splity\n",
    "    train = load_coco(TRAIN_PATH)\n",
    "    val = load_coco(VAL_PATH)\n",
    "    test = load_coco(TEST_PATH)\n",
    "    \n",
    "    data = {\n",
    "        'images': train['images'] + val['images'] + test['images'],\n",
    "        'annotations': train['annotations'] + val['annotations'] + test['annotations'],\n",
    "        'categories': train.get('categories', [])\n",
    "    }\n",
    "    print(f'Wczytano z splitów train/val/test')\n",
    "else:\n",
    "    print('Brak plików anotacji - używam danych przykładowych')\n",
    "    data = {'images': [], 'annotations': [], 'categories': []}\n",
    "\n",
    "images = data.get('images', [])\n",
    "annotations = data.get('annotations', [])\n",
    "categories = data.get('categories', [])\n",
    "\n",
    "print(f'\\nWczytano:')\n",
    "print(f'  - Obrazy: {len(images)}')\n",
    "print(f'  - Anotacje: {len(annotations)}')\n",
    "print(f'  - Kategorie: {len(categories)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ogólne Statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawowe statystyki\n",
    "total_images = len(images)\n",
    "total_annotations = len(annotations)\n",
    "\n",
    "# Anotacje per obraz\n",
    "ann_per_image = defaultdict(int)\n",
    "for ann in annotations:\n",
    "    ann_per_image[ann.get('image_id')] += 1\n",
    "\n",
    "ann_counts = list(ann_per_image.values())\n",
    "\n",
    "stats = {\n",
    "    'Łącznie obrazów': total_images,\n",
    "    'Łącznie anotacji': total_annotations,\n",
    "    'Średnio anotacji/obraz': np.mean(ann_counts) if ann_counts else 0,\n",
    "    'Min anotacji/obraz': min(ann_counts) if ann_counts else 0,\n",
    "    'Max anotacji/obraz': max(ann_counts) if ann_counts else 0,\n",
    "    'Mediana anotacji/obraz': np.median(ann_counts) if ann_counts else 0,\n",
    "}\n",
    "\n",
    "# Wyświetl tabelę\n",
    "stats_df = pd.DataFrame(list(stats.items()), columns=['Metryka', 'Wartość'])\n",
    "stats_df['Wartość'] = stats_df['Wartość'].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram anotacji per obraz\n",
    "if ann_counts:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(ann_counts, bins=range(1, max(ann_counts) + 2), edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Liczba anotacji na obraz')\n",
    "    plt.ylabel('Liczba obrazów')\n",
    "    plt.title('Rozkład liczby anotacji per obraz')\n",
    "    plt.xticks(range(1, max(ann_counts) + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/reports/figures/annotations_per_image.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Brak danych do wykresu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rozkład Emocji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrakcja emocji\n",
    "emotions = []\n",
    "emotion_confidences = defaultdict(list)\n",
    "\n",
    "for ann in annotations:\n",
    "    emotion = ann.get('emotion', {})\n",
    "    if isinstance(emotion, dict):\n",
    "        name = emotion.get('name', 'unknown')\n",
    "        conf = emotion.get('confidence', 0)\n",
    "    else:\n",
    "        name = str(emotion) if emotion else 'unknown'\n",
    "        conf = 0\n",
    "    \n",
    "    emotions.append(name)\n",
    "    emotion_confidences[name].append(conf)\n",
    "\n",
    "# Zlicz emocje\n",
    "emotion_counts = Counter(emotions)\n",
    "emotion_df = pd.DataFrame(\n",
    "    [(e, c, c/len(emotions)*100) for e, c in emotion_counts.most_common()],\n",
    "    columns=['Emocja', 'Liczba', 'Procent']\n",
    ")\n",
    "\n",
    "display(emotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres rozkładu emocji\n",
    "if emotion_counts:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    colors = sns.color_palette('husl', len(emotion_counts))\n",
    "    labels, values = zip(*emotion_counts.most_common())\n",
    "    \n",
    "    ax1.bar(labels, values, color=colors, edgecolor='black')\n",
    "    ax1.set_xlabel('Emocja')\n",
    "    ax1.set_ylabel('Liczba anotacji')\n",
    "    ax1.set_title('Rozkład emocji w datasecie')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Dodaj wartości na słupkach\n",
    "    for i, (label, value) in enumerate(zip(labels, values)):\n",
    "        ax1.text(i, value + max(values)*0.02, str(value), ha='center', fontsize=10)\n",
    "    \n",
    "    # Wykres kołowy\n",
    "    ax2.pie(values, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax2.set_title('Procentowy rozkład emocji')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/reports/figures/emotion_distribution.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Brak danych o emocjach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rozkład Ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrakcja ras\n",
    "breeds = []\n",
    "breed_confidences = defaultdict(list)\n",
    "\n",
    "for ann in annotations:\n",
    "    breed = ann.get('breed', {})\n",
    "    if isinstance(breed, dict):\n",
    "        name = breed.get('name', 'unknown')\n",
    "        conf = breed.get('confidence', 0)\n",
    "    else:\n",
    "        name = str(breed) if breed else 'unknown'\n",
    "        conf = 0\n",
    "    \n",
    "    breeds.append(name)\n",
    "    breed_confidences[name].append(conf)\n",
    "\n",
    "# Zlicz rasy\n",
    "breed_counts = Counter(breeds)\n",
    "\n",
    "# Top 20 ras\n",
    "top_breeds = breed_counts.most_common(20)\n",
    "breed_df = pd.DataFrame(\n",
    "    [(b, c, c/len(breeds)*100) for b, c in top_breeds],\n",
    "    columns=['Rasa', 'Liczba', 'Procent']\n",
    ")\n",
    "\n",
    "print(f'Łącznie unikalnych ras: {len(breed_counts)}')\n",
    "print('\\nTop 20 ras:')\n",
    "display(breed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres top 20 ras\n",
    "if top_breeds:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    labels, values = zip(*top_breeds)\n",
    "    colors = sns.color_palette('viridis', len(top_breeds))\n",
    "    \n",
    "    bars = plt.barh(range(len(labels)), values, color=colors)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.xlabel('Liczba anotacji')\n",
    "    plt.ylabel('Rasa')\n",
    "    plt.title('Top 20 ras w datasecie')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Dodaj wartości\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(value + max(values)*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                 str(value), va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/reports/figures/breed_distribution.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Brak danych o rasach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analiza Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza keypoints\n",
    "keypoint_stats = {\n",
    "    'total_with_keypoints': 0,\n",
    "    'visible_counts': [],\n",
    "    'per_keypoint_visibility': defaultdict(int),\n",
    "}\n",
    "\n",
    "NUM_KEYPOINTS = 46\n",
    "\n",
    "for ann in annotations:\n",
    "    keypoints = ann.get('keypoints', [])\n",
    "    \n",
    "    if keypoints:\n",
    "        keypoint_stats['total_with_keypoints'] += 1\n",
    "        \n",
    "        # Zlicz widoczne keypoints\n",
    "        visible = 0\n",
    "        for i in range(0, len(keypoints) - 2, 3):\n",
    "            v = keypoints[i + 2]\n",
    "            kp_idx = i // 3\n",
    "            \n",
    "            if v > 0:\n",
    "                visible += 1\n",
    "                keypoint_stats['per_keypoint_visibility'][kp_idx] += 1\n",
    "        \n",
    "        keypoint_stats['visible_counts'].append(visible)\n",
    "\n",
    "print(f\"Anotacje z keypoints: {keypoint_stats['total_with_keypoints']} / {len(annotations)}\")\n",
    "\n",
    "if keypoint_stats['visible_counts']:\n",
    "    visible = keypoint_stats['visible_counts']\n",
    "    print(f\"Średnio widocznych keypoints: {np.mean(visible):.1f}\")\n",
    "    print(f\"Min: {min(visible)}, Max: {max(visible)}, Mediana: {np.median(visible):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres widoczności keypoints\n",
    "if keypoint_stats['visible_counts']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram widocznych keypoints\n",
    "    ax1.hist(keypoint_stats['visible_counts'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax1.set_xlabel('Liczba widocznych keypoints')\n",
    "    ax1.set_ylabel('Liczba anotacji')\n",
    "    ax1.set_title('Rozkład liczby widocznych keypoints')\n",
    "    ax1.axvline(np.mean(keypoint_stats['visible_counts']), color='red', \n",
    "                linestyle='--', label=f\"Średnia: {np.mean(keypoint_stats['visible_counts']):.1f}\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Widoczność per keypoint\n",
    "    if keypoint_stats['per_keypoint_visibility']:\n",
    "        kp_indices = sorted(keypoint_stats['per_keypoint_visibility'].keys())\n",
    "        kp_counts = [keypoint_stats['per_keypoint_visibility'][i] for i in kp_indices]\n",
    "        total = keypoint_stats['total_with_keypoints']\n",
    "        kp_rates = [c / total * 100 for c in kp_counts]\n",
    "        \n",
    "        ax2.bar(kp_indices, kp_rates, alpha=0.7)\n",
    "        ax2.set_xlabel('Indeks keypoint')\n",
    "        ax2.set_ylabel('Procent widoczności')\n",
    "        ax2.set_title('Wskaźnik widoczności per keypoint')\n",
    "        ax2.axhline(np.mean(kp_rates), color='red', linestyle='--', \n",
    "                    label=f\"Średnia: {np.mean(kp_rates):.1f}%\")\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/reports/figures/keypoint_analysis.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Brak danych o keypoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rozkład Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrakcja confidence scores\n",
    "bbox_confidences = []\n",
    "breed_conf_list = []\n",
    "emotion_conf_list = []\n",
    "\n",
    "for ann in annotations:\n",
    "    # BBox confidence\n",
    "    bbox_conf = ann.get('score', ann.get('confidence', 0))\n",
    "    if bbox_conf > 0:\n",
    "        bbox_confidences.append(bbox_conf)\n",
    "    \n",
    "    # Breed confidence\n",
    "    breed = ann.get('breed', {})\n",
    "    if isinstance(breed, dict):\n",
    "        bc = breed.get('confidence', 0)\n",
    "        if bc > 0:\n",
    "            breed_conf_list.append(bc)\n",
    "    \n",
    "    # Emotion confidence\n",
    "    emotion = ann.get('emotion', {})\n",
    "    if isinstance(emotion, dict):\n",
    "        ec = emotion.get('confidence', 0)\n",
    "        if ec > 0:\n",
    "            emotion_conf_list.append(ec)\n",
    "\n",
    "print('Statystyki Confidence Scores:')\n",
    "print(f'\\nBBox Detection:')\n",
    "if bbox_confidences:\n",
    "    print(f'  Średnia: {np.mean(bbox_confidences):.3f}')\n",
    "    print(f'  Mediana: {np.median(bbox_confidences):.3f}')\n",
    "    print(f'  Min: {min(bbox_confidences):.3f}, Max: {max(bbox_confidences):.3f}')\n",
    "\n",
    "print(f'\\nBreed Classification:')\n",
    "if breed_conf_list:\n",
    "    print(f'  Średnia: {np.mean(breed_conf_list):.3f}')\n",
    "    print(f'  Mediana: {np.median(breed_conf_list):.3f}')\n",
    "\n",
    "print(f'\\nEmotion Classification:')\n",
    "if emotion_conf_list:\n",
    "    print(f'  Średnia: {np.mean(emotion_conf_list):.3f}')\n",
    "    print(f'  Mediana: {np.median(emotion_conf_list):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykresy confidence\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# BBox confidence\n",
    "if bbox_confidences:\n",
    "    axes[0].hist(bbox_confidences, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0].set_xlabel('Confidence')\n",
    "    axes[0].set_ylabel('Liczba')\n",
    "    axes[0].set_title(f'BBox Detection\\n(śr: {np.mean(bbox_confidences):.3f})')\n",
    "    axes[0].axvline(np.mean(bbox_confidences), color='red', linestyle='--')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'Brak danych', ha='center', va='center')\n",
    "    axes[0].set_title('BBox Detection')\n",
    "\n",
    "# Breed confidence\n",
    "if breed_conf_list:\n",
    "    axes[1].hist(breed_conf_list, bins=50, edgecolor='black', alpha=0.7, color='forestgreen')\n",
    "    axes[1].set_xlabel('Confidence')\n",
    "    axes[1].set_ylabel('Liczba')\n",
    "    axes[1].set_title(f'Breed Classification\\n(śr: {np.mean(breed_conf_list):.3f})')\n",
    "    axes[1].axvline(np.mean(breed_conf_list), color='red', linestyle='--')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Brak danych', ha='center', va='center')\n",
    "    axes[1].set_title('Breed Classification')\n",
    "\n",
    "# Emotion confidence\n",
    "if emotion_conf_list:\n",
    "    axes[2].hist(emotion_conf_list, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[2].set_xlabel('Confidence')\n",
    "    axes[2].set_ylabel('Liczba')\n",
    "    axes[2].set_title(f'Emotion Classification\\n(śr: {np.mean(emotion_conf_list):.3f})')\n",
    "    axes[2].axvline(np.mean(emotion_conf_list), color='red', linestyle='--')\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, 'Brak danych', ha='center', va='center')\n",
    "    axes[2].set_title('Emotion Classification')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/reports/figures/confidence_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Podsumowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podsumowanie końcowe\n",
    "summary = {\n",
    "    'Dataset': {\n",
    "        'Łącznie obrazów': total_images,\n",
    "        'Łącznie anotacji': total_annotations,\n",
    "        'Unikalne rasy': len(breed_counts),\n",
    "        'Kategorie emocji': len(emotion_counts),\n",
    "    },\n",
    "    'Jakość': {\n",
    "        'Śr. confidence bbox': f\"{np.mean(bbox_confidences):.3f}\" if bbox_confidences else 'N/A',\n",
    "        'Śr. confidence rasa': f\"{np.mean(breed_conf_list):.3f}\" if breed_conf_list else 'N/A',\n",
    "        'Śr. confidence emocja': f\"{np.mean(emotion_conf_list):.3f}\" if emotion_conf_list else 'N/A',\n",
    "        'Anotacje z keypoints': f\"{keypoint_stats['total_with_keypoints']} ({keypoint_stats['total_with_keypoints']/max(len(annotations),1)*100:.1f}%)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "print('=' * 60)\n",
    "print('PODSUMOWANIE DOG FACS DATASET')\n",
    "print('=' * 60)\n",
    "\n",
    "for section, metrics in summary.items():\n",
    "    print(f'\\n{section}:')\n",
    "    print('-' * 40)\n",
    "    for key, value in metrics.items():\n",
    "        print(f'  {key}: {value}')\n",
    "\n",
    "print('\\n' + '=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz statystyki do JSON\n",
    "output_stats = {\n",
    "    'generated': pd.Timestamp.now().isoformat(),\n",
    "    'dataset': {\n",
    "        'total_images': total_images,\n",
    "        'total_annotations': total_annotations,\n",
    "        'unique_breeds': len(breed_counts),\n",
    "        'emotion_categories': len(emotion_counts),\n",
    "    },\n",
    "    'emotion_distribution': dict(emotion_counts),\n",
    "    'breed_distribution': dict(breed_counts.most_common(50)),\n",
    "    'confidence_stats': {\n",
    "        'bbox': {\n",
    "            'mean': float(np.mean(bbox_confidences)) if bbox_confidences else 0,\n",
    "            'median': float(np.median(bbox_confidences)) if bbox_confidences else 0,\n",
    "        },\n",
    "        'breed': {\n",
    "            'mean': float(np.mean(breed_conf_list)) if breed_conf_list else 0,\n",
    "            'median': float(np.median(breed_conf_list)) if breed_conf_list else 0,\n",
    "        },\n",
    "        'emotion': {\n",
    "            'mean': float(np.mean(emotion_conf_list)) if emotion_conf_list else 0,\n",
    "            'median': float(np.median(emotion_conf_list)) if emotion_conf_list else 0,\n",
    "        },\n",
    "    },\n",
    "    'keypoints': {\n",
    "        'annotations_with_keypoints': keypoint_stats['total_with_keypoints'],\n",
    "        'avg_visible': float(np.mean(keypoint_stats['visible_counts'])) if keypoint_stats['visible_counts'] else 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "output_path = Path('../docs/reports/dataset_statistics.json')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f'Statystyki zapisane do: {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
