{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 5: Emotion Classification Model\n",
    "\n",
    "**Цель:** Accuracy > 70% на 4 классах эмоций\n",
    "\n",
    "**Подход:** Два варианта:\n",
    "1. **Image-based**: EfficientNet на изображениях (простой)\n",
    "2. **Keypoint-based**: MLP на keypoints features (научный)\n",
    "\n",
    "**Классы эмоций:**\n",
    "- 0: sad\n",
    "- 1: angry\n",
    "- 2: relaxed\n",
    "- 3: happy\n",
    "\n",
    "**Датасет:** HuggingFace Dewa/Dog_Emotion_Dataset_v2 (4000 изображений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers timm pillow scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Загрузка датасета\n",
    "print(\"Загрузка датасета с HuggingFace...\")\n",
    "dataset = load_dataset(\"Dewa/Dog_Emotion_Dataset_v2\")\n",
    "print(f\"Train: {len(dataset['train'])} images\")\n",
    "print(f\"Test: {len(dataset['test'])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка структуры\n",
    "print(\"\\nПример записи:\")\n",
    "sample = dataset['train'][0]\n",
    "print(f\"  Label: {sample['label']}\")\n",
    "print(f\"  Emotion: {sample['emotion']}\")\n",
    "print(f\"  Image size: {sample['image'].size}\")\n",
    "\n",
    "# Классы эмоций\n",
    "EMOTION_CLASSES = ['sad', 'angry', 'relaxed', 'happy']\n",
    "NUM_CLASSES = len(EMOTION_CLASSES)\n",
    "\n",
    "# Статистика по классам\n",
    "print(\"\\nРаспределение классов (train):\")\n",
    "from collections import Counter\n",
    "train_labels = [x['label'] for x in dataset['train']]\n",
    "for label, count in sorted(Counter(train_labels).items()):\n",
    "    print(f\"  {EMOTION_CLASSES[label]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация примеров\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, emotion in enumerate(EMOTION_CLASSES):\n",
    "    # Находим примеры для каждого класса\n",
    "    examples = [x for x in dataset['train'] if x['emotion'] == emotion][:2]\n",
    "    for j, ex in enumerate(examples):\n",
    "        ax = axes[j, i]\n",
    "        ax.imshow(ex['image'])\n",
    "        ax.set_title(f\"{emotion.upper()}\")\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_examples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Вариант A: Image-based Classification (EfficientNet)\n",
    "\n",
    "Простой и эффективный подход - fine-tuning CNN на изображениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset для PyTorch\n",
    "class EmotionImageDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.data = hf_dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = item['image'].convert('RGB')\n",
    "        label = item['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = EmotionImageDataset(dataset['train'], train_transform)\n",
    "test_dataset = EmotionImageDataset(dataset['test'], val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# Создание модели\n",
    "def create_emotion_model(model_name='efficientnet_b0', num_classes=4):\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# Устройство\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Модель\n",
    "model = create_emotion_model('efficientnet_b0', NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss и optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "print(f\"\\nМодель: EfficientNet-B0\")\n",
    "print(f\"Параметры: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции обучения\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Evaluating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "EPOCHS = 20\n",
    "best_acc = 0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ОБУЧЕНИЕ IMAGE-BASED МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'emotion_image_best.pt')\n",
    "        print(f\"  → Сохранена лучшая модель: {val_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ЛУЧШАЯ ACCURACY: {best_acc:.2f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График обучения\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train')\n",
    "ax1.plot(history['val_loss'], label='Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train')\n",
    "ax2.plot(history['val_acc'], label='Validation')\n",
    "ax2.axhline(y=70, color='r', linestyle='--', label='Target (70%)')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_training_curve.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальная оценка\n",
    "model.load_state_dict(torch.load('emotion_image_best.pt'))\n",
    "_, final_acc, preds, labels = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ФИНАЛЬНАЯ ОЦЕНКА (Image-based Model)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTest Accuracy: {final_acc:.2f}%\")\n",
    "print(f\"Target: 70%\")\n",
    "print(f\"Status: {'PASS ✓' if final_acc >= 70 else 'FAIL ✗'}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=EMOTION_CLASSES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(EMOTION_CLASSES))\n",
    "plt.xticks(tick_marks, EMOTION_CLASSES, rotation=45)\n",
    "plt.yticks(tick_marks, EMOTION_CLASSES)\n",
    "for i in range(len(EMOTION_CLASSES)):\n",
    "    for j in range(len(EMOTION_CLASSES)):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение метрик\n",
    "metrics = {\n",
    "    'model_type': 'image_based',\n",
    "    'architecture': 'efficientnet_b0',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'emotion_classes': EMOTION_CLASSES,\n",
    "    'best_val_accuracy': best_acc,\n",
    "    'final_test_accuracy': final_acc,\n",
    "    'epochs': EPOCHS,\n",
    "    'target_accuracy': 70.0,\n",
    "    'passed': final_acc >= 70.0,\n",
    "}\n",
    "\n",
    "with open('emotion_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Сохранённые файлы:\")\n",
    "print(\"  - emotion_image_best.pt (веса модели)\")\n",
    "print(\"  - emotion_metrics.json (метрики)\")\n",
    "print(\"  - emotion_training_curve.png (график обучения)\")\n",
    "print(\"  - emotion_confusion_matrix.png (матрица ошибок)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Копирование в /kaggle/working/ для скачивания\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "output_dir = '/kaggle/working/'\n",
    "if os.path.exists(output_dir):\n",
    "    for f in ['emotion_image_best.pt', 'emotion_metrics.json', \n",
    "              'emotion_training_curve.png', 'emotion_confusion_matrix.png',\n",
    "              'emotion_examples.png']:\n",
    "        if os.path.exists(f):\n",
    "            shutil.copy(f, output_dir)\n",
    "            print(f\"Скопировано: {f}\")\n",
    "else:\n",
    "    print(\"Локальный режим - файлы в текущей директории\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Итоги\n",
    "\n",
    "### Image-based Model (EfficientNet-B0)\n",
    "- Простой и эффективный подход\n",
    "- Использует transfer learning\n",
    "- Подходит для production\n",
    "\n",
    "### Следующие шаги\n",
    "1. Скачать `emotion_image_best.pt`\n",
    "2. Добавить в `packages/models/emotion.py`\n",
    "3. Интегрировать в full_pipeline.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
