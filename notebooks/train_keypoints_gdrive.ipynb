{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Keypoints - Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "SAVE_DIR = '/content/drive/MyDrive/dogfacs_keypoints'\n",
    "!mkdir -p {SAVE_DIR}\n",
    "print(f\"Files will be saved to: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"dreadhorse\"\n",
    "os.environ['KAGGLE_KEY'] = \"KGAT_9b0180da358cafd8fdde273e4f84c7cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d georgemartvel/dogflw -p /content/data --unzip --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "DATA = Path(\"/content/data/DogFLW\")\n",
    "NUM_KP = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(name):\n",
    "    imgs = DATA/name/\"images\"\n",
    "    labs = DATA/name/\"labels\"\n",
    "    out = []\n",
    "    for js in labs.glob(\"*.json\"):\n",
    "        im = None\n",
    "        for e in [\".png\",\".jpg\",\".PNG\",\".JPG\"]:\n",
    "            c = imgs/f\"{js.stem}{e}\"\n",
    "            if c.exists(): im=c; break\n",
    "        if not im: continue\n",
    "        try:\n",
    "            with open(js) as f: d=json.load(f)\n",
    "            kp = np.array(d[\"landmarks\"][:NUM_KP], dtype=np.float32)\n",
    "            if not np.isnan(kp).any() and (kp>=0).all():\n",
    "                out.append({\"img\":str(im),\"kp\":kp})\n",
    "        except: pass\n",
    "    print(f\"{name}: {len(out)}\")\n",
    "    return out\n",
    "\n",
    "train_raw = load_split(\"train\")\n",
    "test_data = load_split(\"test\")\n",
    "random.shuffle(train_raw)\n",
    "val_data = train_raw[int(0.9*len(train_raw)):]\n",
    "train_data = train_raw[:int(0.9*len(train_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, data, aug=False):\n",
    "        self.data=data\n",
    "        self.tf=transforms.Compose([transforms.ToTensor(),transforms.Normalize([.485,.456,.406],[.229,.224,.225])])\n",
    "        self.aug=A.Compose([A.HorizontalFlip(p=0.5),A.Rotate(limit=15,p=0.5),A.RandomBrightnessContrast(p=0.3)],keypoint_params=A.KeypointParams(format=\"xy\",remove_invisible=False)) if aug else None\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        d=self.data[i]\n",
    "        im=Image.open(d[\"img\"]).convert(\"RGB\")\n",
    "        ow,oh=im.size\n",
    "        kp=d[\"kp\"].copy()\n",
    "        im=im.resize((256,256))\n",
    "        kp[:,0]*=256/ow; kp[:,1]*=256/oh\n",
    "        kp=np.clip(kp,0,255)\n",
    "        if self.aug:\n",
    "            try:\n",
    "                r=self.aug(image=np.array(im),keypoints=[(k[0],k[1]) for k in kp])\n",
    "                im=Image.fromarray(r[\"image\"])\n",
    "                kp=np.clip(np.array(r[\"keypoints\"],dtype=np.float32),0,255)\n",
    "            except: pass\n",
    "        hm=np.zeros((NUM_KP,64,64),dtype=np.float32)\n",
    "        for k in range(NUM_KP):\n",
    "            x,y=int(kp[k,0]/4),int(kp[k,1]/4)\n",
    "            x,y=max(0,min(63,x)),max(0,min(63,y))\n",
    "            for di in range(-3,4):\n",
    "                for dj in range(-3,4):\n",
    "                    yi,xj=y+di,x+dj\n",
    "                    if 0<=yi<64 and 0<=xj<64: hm[k,yi,xj]=np.exp(-(di**2+dj**2)/8)\n",
    "        return self.tf(im),torch.from_numpy(hm),torch.from_numpy(kp)\n",
    "\n",
    "train_ds=DS(train_data,aug=True)\n",
    "val_ds=DS(val_data)\n",
    "test_ds=DS(test_data)\n",
    "train_ld=DataLoader(train_ds,batch_size=32,shuffle=True,num_workers=0)\n",
    "val_ld=DataLoader(val_ds,batch_size=32,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bb=timm.create_model(\"resnet50\",pretrained=True,features_only=True,out_indices=[-1])\n",
    "        self.head=nn.Sequential(nn.ConvTranspose2d(2048,256,4,2,1),nn.BatchNorm2d(256),nn.ReLU(True),nn.ConvTranspose2d(256,256,4,2,1),nn.BatchNorm2d(256),nn.ReLU(True),nn.ConvTranspose2d(256,256,4,2,1),nn.BatchNorm2d(256),nn.ReLU(True))\n",
    "        self.out=nn.Conv2d(256,NUM_KP,1)\n",
    "    def forward(self,x): return self.out(self.head(self.bb(x)[-1]))\n",
    "\n",
    "model=Model().to(device)\n",
    "def decode(hm):\n",
    "    B,K,H,W=hm.shape\n",
    "    kp=torch.zeros(B,K,2)\n",
    "    for b in range(B):\n",
    "        for k in range(K):\n",
    "            idx=hm[b,k].argmax()\n",
    "            kp[b,k,0]=(idx%W)*4\n",
    "            kp[b,k,1]=(idx//W)*4\n",
    "    return kp\n",
    "def pck(p,g,th=0.1): return (torch.sqrt(((p-g)**2).sum(-1))<th*256).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit=nn.MSELoss()\n",
    "opt=optim.AdamW(model.parameters(),lr=1e-4,weight_decay=1e-4)\n",
    "sch=optim.lr_scheduler.CosineAnnealingLR(opt,50)\n",
    "best=0\n",
    "hist=[]\n",
    "\n",
    "for ep in range(50):\n",
    "    model.train()\n",
    "    for x,hm,_ in tqdm(train_ld,leave=False,desc=f\"Ep{ep+1}\"):\n",
    "        x,hm=x.to(device),hm.to(device)\n",
    "        opt.zero_grad()\n",
    "        crit(model(x),hm).backward()\n",
    "        opt.step()\n",
    "    model.eval()\n",
    "    pk=[]\n",
    "    with torch.no_grad():\n",
    "        for x,hm,gt in val_ld:\n",
    "            pk.append(pck(decode(model(x.to(device)).cpu()),gt))\n",
    "    sch.step()\n",
    "    vp=np.mean(pk)\n",
    "    hist.append(vp)\n",
    "    m=\"\"\n",
    "    if vp>best:\n",
    "        best=vp\n",
    "        torch.save(model.state_dict(),f\"{SAVE_DIR}/keypoints_best.pt\")\n",
    "        m=\" * SAVED TO DRIVE\"\n",
    "    print(f\"Ep{ep+1:2d} PCK:{vp*100:.1f}%{m}\")\n",
    "print(f\"\\nBest: {best*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([p*100 for p in hist])\n",
    "plt.axhline(75,color=\"r\",ls=\"--\")\n",
    "plt.title(f\"Best PCK: {best*100:.1f}%\")\n",
    "plt.savefig(f\"{SAVE_DIR}/curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ld=DataLoader(test_ds,batch_size=32,num_workers=0)\n",
    "model.load_state_dict(torch.load(f\"{SAVE_DIR}/keypoints_best.pt\"))\n",
    "model.eval()\n",
    "tp=[]\n",
    "with torch.no_grad():\n",
    "    for x,_,gt in test_ld:\n",
    "        tp.append(pck(decode(model(x.to(device)).cpu()),gt))\n",
    "test_pck=np.mean(tp)\n",
    "print(\"=\"*40)\n",
    "print(f\"TEST PCK: {test_pck*100:.1f}%\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "with open(f\"{SAVE_DIR}/metrics.json\",\"w\") as f:\n",
    "    json.dump({\"best_val_pck\":best,\"test_pck\":test_pck},f)\n",
    "print(f\"\\nSaved to Google Drive: {SAVE_DIR}\")\n",
    "!ls -la {SAVE_DIR}"
   ]
  }
 ],
 "metadata": {"accelerator":"GPU","kernelspec":{"display_name":"Python 3","name":"python3"}},
 "nbformat": 4,
 "nbformat_minor": 0
}
